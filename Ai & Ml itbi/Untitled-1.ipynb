{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import matplotlib.pyplot as plt\n",
    "from wordcloud import WordCloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('AmazonReview.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "data.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#1,2,3->negative(i.e 0)\n",
    "data.loc[data['Sentiment']<=3,'Sentiment'] = 0\n",
    "\n",
    "#4,5->positive(i.e 1)\n",
    "data.loc[data['Sentiment']>3,'Sentiment'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stp_words=stopwords.words('english')\n",
    "def clean_review(review):\n",
    "  cleanreview=\" \".join(word for word in review.\n",
    "                       split() if word not in stp_words)\n",
    "  return cleanreview\n",
    "\n",
    "data['Review']=data['Review'].apply(clean_review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Sentiment'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated=' '.join(word for word in data['Review'][data['Sentiment']==0].astype(str))\n",
    "wordCloud=WordCloud(width=1600,height=800,random_state=21,max_font_size=110)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordCloud.generate(consolidated),interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "consolidated=' '.join(word for word in data['Review'][data['Sentiment']==1].astype(str))\n",
    "wordCloud=WordCloud(width=1600,height=800,random_state=21,max_font_size=110)\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.imshow(wordCloud.generate(consolidated),interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = TfidfVectorizer(max_features=2500)\n",
    "X = cv.fit_transform(data['Review'] ).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train ,x_test,y_train,y_test=train_test_split(X,data['Sentiment'],\n",
    "\t\t\t\t\t\t\t\t\t\t\t\ttest_size=0.25 ,\n",
    "\t\t\t\t\t\t\t\t\t\t\t\trandom_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model=LogisticRegression()\n",
    "\n",
    "#Model fitting\n",
    "model.fit(x_train,y_train)\n",
    "\n",
    "#testing the model\n",
    "pred=model.predict(x_test)\n",
    "\n",
    "#model accuracy\n",
    "print(accuracy_score(y_test,pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "cm = confusion_matrix(y_test,pred)\n",
    "\n",
    "cm_display = metrics.ConfusionMatrixDisplay(confusion_matrix = cm,\n",
    "\t\t\t\t\t\t\t\t\t\t\tdisplay_labels = [False, True])\n",
    "\n",
    "cm_display.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
